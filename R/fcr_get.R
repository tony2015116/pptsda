# WARNING - Generated by {fusen} from /dev/flat_teaching.Rmd: do not edit by hand

#' FCR get from pig performance test station csv data
#' 
#' @param data A data frame or data table containing the nedap or fire pig performance test data to be processed. Columns must include 'visit_time', 'location', 'responder', 'feed_intake'.
#' @param my_break Optional, a numeric vector of length 2, indicates target weight range for calculating ADG, default NULL. If not NULL, ADG will be calculated within this range.
#' @param range_offset Optional, a numeric value, default 0.5. 
#' Used to extend the target weight range specified in my_break to avoid border effect.
#' For example, if my_break is c(60,90) and range_offset is 0.5, the actual range for analysis will be 57.5~92.5.
#' @param threshold Optional, a numeric value, default 1, used as the threshold to identify outliers in RANSAC regression, usually 0~2.
#' @param save_path Optional, a character string specifying where to save the generated growth curve images. If not NULL, images will be saved to this path.
#' 
#' @export

#' @examples
#' data <- rio::import("C:/Users/Dell/Downloads/ppt_test_data.xlsx")
#' fcr_res <- fcr_get(data = data, my_break = c(30, 100))
fcr_get <- function(data, my_break = NULL, range_offset = 0.5, threshold = 1, save_path = NULL) {
  . <-  .GRP <- .N <- .SD <- `:=` <- N <- color_judge <- data_na_greater_than_one_third <- date_length <- 
    date_na <- day_diff <- day_text <- end_date_cut <- end_date_origin <- error_msg <- lm_predict <-
    lm_slope <- location <- location_maxn <- max_weight <- max_weight_cut <- max_weight_origin <- mean_residual <- 
      min_weight <- min_weight_cut <- min_weight_origin <- model_lmrob <- n <- n_days <- n_responders <- 
      outliers <-  r_squared <- responder <- row_sum <- safe_lm <- safe_lmrob <- sd_residual <- seq_days <- 
      seq_in_day <- seq_in_location <- stage <- stage_days <- start_date_cut <- start_date_origin <- temp <- 
      test_days_less_than_40 <- test_records_less_than_20 <- visit_time <- warning_msg <- 
    ..col_names <- OE <- dfi_error_part <- dfi_right_part <- duration <- 
    entrancefeedweight <- entrancetime <- exitfeedweight <- exittime <- feed_intake <- fiv <- 
    fiv_0  <- fiv_hi <- fiv_lo <- frv <- frv_0 <- frv_hi <- frv_hi_fiv_lo <- frv_hi_strict <- 
      frv_lo <- ftd <- ftd_lo <- fwd <- fwd_hi <- fwd_lo <- lm_slope <- 
      ltd <- ltd_lo <- lwd <- lwd_hi <- lwd_lo <- otv <- otv_hi <- otv_lo <- weight <- 
    fcr <- corrected_dfi <- cor_fcr <- NULL
  
  #caculate mode
  adg_get <- function(data, my_break = my_break, range_offset = range_offset, threshold = threshold, save_path = save_path) {
    #根据不同用途，分多个函数模块，各模块的数据输出和输入是衔接的
    #process_data对原始csv进行预处理，找出有重复responder并做处理
    process_data <- function(data) {
      if (missing(data)) stop("Missing data frame or data table!")
      if (!is.data.frame(data) && !inherits(data, "data.table")) stop("Data is not a data frame or data table!")

      # Check for required columns
      required_columns <- c("animal_number", "lifenumber", "responder", "location", "visit_time", "duration", "state", "weight", "feed_intake")
      missing_columns <- setdiff(required_columns, names(data))
      if (length(missing_columns) > 0) stop(paste("Missing columns:", paste(missing_columns, collapse = ", ")))

      # Check types for some columns
      if (!is.numeric(data$animal_number)) stop("'animal_number' must be numeric!")
      if (!is.logical(data$lifenumber) && !is.character(data$lifenumber)) stop("'lifenumber' must be logical or character!")
      if (!is.numeric(data$responder)) stop("'responder' must be numeric!")
      if (!is.numeric(data$location)) stop("'location' must be numeric!")
      if (!is.character(data$visit_time) && !inherits(data$visit_time, "POSIXt")) stop("'visit_time' must be character or POSIXct!")
      if (!is.numeric(data$duration)) stop("'duration' must be numeric!")
      if (!is.numeric(data$state)) stop("'state' must be numeric!")
      if (!is.numeric(data$weight)) stop("'weight' must be numeric!")
      if (!is.numeric(data$feed_intake)) stop("'feed_intake' must be numeric!")

      # Check if the data is a data.frame, if yes, then make a deep copy of the data and convert it into data.table
      if (is.data.frame(data)) data <- data.table::as.data.table(data.table::copy(data))

      # Filter out the data with NA in 'responder' column and remove duplicates
      data_temp <- unique(data)[!is.na(responder)]

      # Create a unique data.table for 'responder' and 'location'
      unique_dt <- unique(data_temp[, .(responder, location)])

      # Find duplicate 'responder's
      dup_responders <- unique_dt[, .N, by = .(responder)][N > 1]

      # Compute the number of records for each 'responder' and 'location'
      num_records <- unique(data_temp[, `:=`(n, .N), .(responder, location)][, .(responder, location, n)])

      # Set 'responder' as the key for join operations
      data.table::setkey(dup_responders, responder)
      data.table::setkey(num_records, responder)

      # Perform left join operation on 'num_records' and 'dup_responders'
      dup_records <- num_records[dup_responders]

      # Print duplicate 'responder's and their 'location's
      if(nrow(dup_records) > 0) {
        cat(crayon::red("\u2022 There are", length(unique(dup_records$responder)), "duplicated responders.\n"))
        print(dup_records)
      } else {
        cat(crayon::green("\u2022 There are no duplicate responders in different locations.\n"))
      }

      # Modify the 'location' in the unique data.table for duplicate 'responder's
      if(nrow(dup_responders) > 0) {
        # Compute the 'location' with maximum number of records for each 'responder'
        max_n_location <- num_records[, .(max_n = max(n), location_maxn = location[which.max(n)]), by = responder]

        # Remove duplicates in 'max_n_location' after modifying 'location'
        max_n_location <- unique(max_n_location)

        # Perform left join operation on 'data_temp' and 'max_n_location' and update 'location' to 'location_maxn'
        data_temp <- merge(data_temp, max_n_location, by = "responder", all.x = TRUE)[, location := location_maxn][, c("max_n", "location_maxn") := NULL]
      }

      # Preprocess data and compute sequence features
      # Check the class of visit_time
      if(is.character(data_temp$visit_time)) {
        # If visit_time is a character vector, replace "/" with "-"
        data_temp[, visit_time := gsub("/", "-", visit_time)]
        data_pre <- data_temp[, `:=`(c("date", "time"), data.table::IDateTime(visit_time))]
      } else {
        # If visit_time is not a character vector, assume it's a datetime object
        data_pre <- data_temp[, `:=`(c("date", "time"), data.table::IDateTime(visit_time))]
      }
      data_pre <- data_pre[data.table::CJ(date = tidyr::full_seq(date, 1)), on = .(date)  # Compute complete sequence of dates
      ][order(date), `:=`(seq_days, .GRP), by = date  # Compute sequence number of days
      ][order(visit_time), `:=`(seq_in_day, 1:.N), by = .(responder, date)  # Compute sequence number in day
      ][order(visit_time), `:=`(seq_in_location, 1:.N), by = .(location, date)  # Compute sequence number in location
      ][order(responder, visit_time)  # Order data by 'responder' and 'visit_time'
      ][, .(responder, location, date, seq_in_location, seq_days, seq_in_day, weight)  # Keep only necessary columns
      ][, `:=` (responder = as.character(responder),  # Convert 'responder' and 'location' to character type
                location = as.character(location),
                weight = as.numeric(weight))][]  # Convert 'weight' to numeric type
      return(data_pre)
    }
    #删除整个test阶段体重小于15kg的记录，看是否会因此删掉responder.同时删除因为各类型因数据缺失而淘汰的responder的记录
    clean_step1 <- function(data) {
      # 选出所有responder
      all_responder <- unique(data[!is.na(responder), .(responder)])
      # 选出至少有一个weight >= 15000的responder
      responder_with_weight_ge_15000 <- unique(data[weight >= 15000, .(responder)])

      # 找出所有的weight都小于15000的responder
      responder_to_delete <- all_responder[!responder_with_weight_ge_15000, on = "responder"]

      # 打印删除的responder的数量
      if(nrow(responder_to_delete) > 0){
        cat(crayon::red("\u2022 Revoming weight < 15kg records will delete responders: ", nrow(responder_to_delete), "\n"))
      } else {
        cat(crayon::green("\u2022 The removing of weight < 15kg will not delete responder.\n"))
      }

      # 删除因为删除weight < 15kg而被删除的responder的records
      temp1 <- data[!responder %in% responder_to_delete$responder]

      # 过滤和处理数据
      temp2 <- temp1[, `:=`(n, .N), .(responder, location) #temp6是temp2, temp5是temp1
      ][, `:=`(date_na, sum(is.na(weight))), .(location, responder)
      ][, `:=`(date_length, as.integer(difftime(max(date), min(date), units = "days"))), responder][, `:=`(
        test_days_less_than_40 = ifelse(date_length < 35, 1, 0),
        test_records_less_than_20 = ifelse(n < 20, 1, 0),
        data_na_greater_than_one_third = ifelse(date_length == 0, 0, ifelse(date_na/date_length >= 1/3, 1, 0))
      )]
      # Assuming your data.table is dt
      temp3 = temp2[, row_sum := rowSums(.SD), .SDcols = c("date_na", "test_days_less_than_40", "test_records_less_than_20", "data_na_greater_than_one_third")]#temp7是temp3
      outlier <- unique(temp3[,.(responder, location, date_na, test_days_less_than_40, test_records_less_than_20, data_na_greater_than_one_third, row_sum)])[row_sum > 0]

      #在此处删除整个测定阶段记录weight < 15kg 的记录
      step1_res <- temp3[row_sum==0][weight >= 15000][, .(responder, location, date, seq_in_location, seq_days, seq_in_day, weight)]

      if(nrow(outlier) > 0){
        # 打印删除的行数
        cat(crayon::red("\u2022 Revoming records of missing will delete responders: ", nrow(outlier), "\n"))
      } else {
        print(crayon::green("\u2022 No responder is deleted due to missing records."))
      }

      deleted_responders <- c(responder_to_delete$responder, outlier$responder)
      cat(crayon::red('\u2022 Deleted responders: \n', paste0('c("', paste(deleted_responders, collapse = '","'), '")'), "\n"))


      # Check if the processed data has zero rows
      if (nrow(step1_res) == 0) {
        stop("The processed data is empty!")
      }

      return(step1_res)
    }
    #运行RANSA robust鲁棒回归模型，确定离群值，看是否会因为仅仅剔除离群值就会淘汰responder
    clean_step2 <- function(data, threshold) {

      # Add argument checks
      if (!data.table::is.data.table(data)) {
        stop("Argument 'data' should be of class data.table")
      }

      if (!is.numeric(threshold) || length(threshold) != 1 || threshold < 0 || threshold > 2) {
        stop("Argument 'threshold' should be a single numeric value between 0 and 2")
      }

      #统计data开始时的responder
      begin_responder <- unique(data[, .(responder)])

      # 最后生成嵌套数据格式
      data <- data[, .(data = list(.SD)), by = responder]

      # Check for errors and warnings and print messages
      check_errors_and_warnings <- function(data) {
        # Check for errors
        if (any(data[, error_msg != ""])) {
          cat(crayon::red(" - Errors encountered during processing:\n"))
          cat(data[data[, error_msg != ""], .(responder, error_msg)], sep = "\n")
        } else {
          cat(crayon::blue(" - No errors encountered during processing.\n"))
        }

        # Check for warnings
        if (any(data[, warning_msg != ""])) {
          cat(crayon::red(" - Warnings encountered during processing:\n"))
          cat(data[data[, warning_msg != ""], .(responder, warning_msg)], sep = "\n")
        } else {
          cat(crayon::blue(" - No warnings encountered during processing.\n"))
        }
      }

      # 使用RANSAC进行鲁棒线性回归
      process_lmrob_results <- function(data, threshold, ...) {
        safelmrob <- purrr::safely(.f = robustbase::lmrob)
        temp1 <- data[, `:=`(safe_lmrob, purrr::map(data, function(df, ...) safelmrob(..., data = df), ...))
        ][, `:=`(model_lmrob, purrr::map(safe_lmrob, function(x) x$result))
        ][, `:=`(error_msg, purrr::map_chr(safe_lmrob, function(x) if (is.null(x$error)) "" else x$error$message))
        ][, `:=`(warning_msg, purrr::map_chr(safe_lmrob, function(x) if (is.null(x$warning)) "" else x$warning$message))
        ][, `:=`(residuals, purrr::pmap(list(model_lmrob, error_msg, warning_msg), function(x, e, w) {
          if (e == "" && w == "") {return(residuals(x))} else {return(NULL)}}))
        ][, `:=`(predict, purrr::pmap(list(model_lmrob, error_msg, warning_msg), function(x, e, w) {
          if (e == "" && w == "") {return(predict(x))} else {return(NULL)}}))
        ][, `:=`(mean_residual, purrr::map_dbl(residuals, mean, na.rm = TRUE))
        ][, `:=`(sd_residual, purrr::map_dbl(residuals, sd, na.rm = TRUE))
        ][, `:=`(outliers, purrr::pmap(list(residuals, mean_residual, sd_residual), function(r, m, sd) {
          if (length(r) > 0) {return(abs(r - m) > threshold * sd)} else {return(NULL)}}))
        ][]#
        # Print message
        cat(crayon::white("\u2022 Check for errors and warnings in RANSAC Robust\n"))
        check_errors_and_warnings(temp1)
        temp2 = temp1[, c("safe_lmrob","model_lmrob","error_msg","warning_msg","residuals","mean_residual","sd_residual") := NULL
        ][, tidyfst::unchop_dt(.SD), .SDcol = c("data", "predict", "outliers"), by = responder]
        return(temp2)
      }

      # 函数调用
      final <- tryCatch({
        # 设置RANSAC参数
        control <- robustbase::lmrob.control(tuning.chi = 1.548, k.max = 1000, maxit.scale = 1000, max.it = 1000)
        lm_results <- process_lmrob_results(data = data, threshold = threshold, weight ~ seq_days + I(seq_days^2), control= control)
        cat(crayon::green(" - RANSAC Robust succeeded\n"))
        lm_results #########必须有该行
      }, error = function(e) {
        cat(crayon::red("\u2022 Error: ", conditionMessage(e), "\n"))
        stop("Execution error, the program has stopped")
      })

      #统计删除outlier后的responder
      end_reponder <- unique(final[outliers == FALSE])
      responder_to_delete <- begin_responder[!end_reponder, on = "responder"]
      deleted_responders <- responder_to_delete$responders
      # 打印删除的responder的数量
      if(nrow(responder_to_delete) > 0){
        cat(crayon::red("\u2022 Detecting outliers using model will delete responders: ", nrow(responder_to_delete), "\n"))
        cat(crayon::red('\u2022 Deleted responders: \n', paste0('c("', paste(deleted_responders, collapse = '","'), '")'), "\n"))
      } else {
        cat(crayon::green("\u2022 The outliers detected by model will not delete responder.\n"))
      }

      # 删除所有的因删除outlier而损失的responder。并且删除outliter
      final <- final[!responder %in% responder_to_delete$responder]

      return(final)
    }
    #删除进站体重大于60kg,出站体重小于85kg的猪只记录
    clean_step3 <- function(data) {
      # 获取最大最站体重和最小出站体重
      handle_data <- function(data, seq_days, direction, weight_type) {
        data <- data[, keyby = .(responder), `:=`(temp, data.table::frankv(direction * seq_days, ties.method = "dense") <= 1)
        ][temp == TRUE]
        data <- data[, keyby = .(responder, location), .(temp_weight = mean(predict))]
        data.table::setnames(data, "temp_weight", weight_type)
        return(data)
      }

      temp0 <- data[outliers == FALSE]
      # 处理数据，包括筛选体重和计算lm()预测体重平均值
      temp1 <- handle_data(data = temp0, seq_days, 1, "min_weight")

      # 查找所有体重超过60000的responder
      overweight_responders <- unique(temp1[min_weight > 60000, .(responder)])

      # 计算超过进站体重上限的responder数量
      num_overweight_responders <- nrow(overweight_responders)

      # 打印超过权重上限的responder数量
      if(num_overweight_responders > 0){
        cat(crayon::red("\u2022 Revoming begin_test_weight > 60kg records will delete responders: ", num_overweight_responders, "\n"))
      } else {
        cat(crayon::green("\u2022 All responders' begin_test_weight are less than or equal to 60kg.\n"))
      }

      # 移除超过权重上限的responder
      temp2 <- data[!responder %in% overweight_responders$responder]

      temp3 <- handle_data(data = temp2, seq_days, -1, "max_weight")

      # 查找所有体重超过85000的responder
      underweight_responders <- unique(temp3[max_weight < 85000, .(responder)])

      # 计算超过权重上限的responder数量
      num_underweight_responders <- nrow(underweight_responders)

      # 打印超过权重上限的responder数量
      if(num_underweight_responders > 0){
        cat(crayon::red("\u2022 Revoming end_test_weight < 85kg records will delete responders: ", num_underweight_responders, "\n"))
        deleted_responders <- c(overweight_responders$responder, underweight_responders$responder)
        cat(crayon::red('\u2022 Deleted responders: \n', paste0('c("', paste(deleted_responders, collapse = '","'), '")'), "\n"))
      } else {
        cat(crayon::green("\u2022 All responders' end_test_weight are more than or equal to 85kg.\n"))
      }

      # 移除超过体重上限的responder
      passed_repsonder <- temp2[!responder %in% underweight_responders$responder][, !c("temp")]
      #filtered_responder <- temp2[responder %in% underweight_responders$responder][, !c("temp")]
      #final <- list(passed_repsonder = passed_repsonder, filtered_responder = filtered_responder)


      #return(final)
      return(passed_repsonder)
    }
    #根据有无特定体重阶段分析需求，分别获取adg
    clean_step4 <- function(data, my_break, range_offset) {

      # Add argument checks
      if (!data.table::is.data.table(data)) {
        stop("Argument 'data' should be of class data.table")
      }

      if (!is.null(my_break) && (!is.numeric(my_break) || length(my_break) != 2 || any(my_break < 0))) {
        stop("Argument 'my_break' should be a numeric vector of length 2 with non-negative values or NULL")
      }

      if (!is.numeric(range_offset) || length(range_offset) != 1 || range_offset < 0 || range_offset > 1) {
        stop("Argument 'range_offset' should be a single numeric value in the range [0, 1]")
      }

      #看情况，最好是过滤掉异常体重数据后再截取体重
      cut_weight <- function(data, my_break, range_offset) {
        if (is.data.frame(data)) data <- data.table::as.data.table(data)

        # 将my_break乘以1000以匹配数据中的体重表示
        my_break <- my_break * 1000

        # 使用给定的范围和范围偏移生成实际的断点
        actual_breaks <- c(my_break[1] - range_offset * 1000, my_break[2] + range_offset * 1000)

        # 选取指定范围内的体重
        data <- data[predict >= actual_breaks[1] & predict <= actual_breaks[2], ]

        # 添加stage列，用于表示选取的体重范围
        data[, `:=`(stage, paste0(my_break[1] / 1000, "-", my_break[2] / 1000))]

        return(data)
      }

      # 获取最大最站体重和最小出站体重
      handle_data <- function(data, seq_days, direction, weight_type) {
        data <- data[, keyby = .(responder), `:=`(temp, data.table::frankv(direction * seq_days, ties.method = "dense") <= 2)
        ][temp == TRUE]
        data <- data[, keyby = .(responder, location), .(temp_weight = stats::median(weight))]
        data.table::setnames(data, "temp_weight", weight_type)
        return(data)
      }

      # Check for errors and warnings and print messages
      check_errors_and_warnings <- function(data) {
        # Check for errors
        if (any(data[, error_msg != ""])) {
          cat(crayon::red(" - Errors encountered during processing:\n"))
          cat(data[data[, error_msg != ""], .(responder, error_msg)], sep = "\n")
        } else {
          cat(crayon::blue(" - No errors encountered during processing.\n"))
        }

        # Check for warnings
        if (any(data[, warning_msg != ""])) {
          cat(crayon::red(" - Warnings encountered during processing:\n"))
          cat(data[data[, warning_msg != ""], .(responder, warning_msg)], sep = "\n")
        } else {
          cat(crayon::blue(" - No warnings encountered during processing.\n"))
        }
      }

      #一般线性模型计算日增重
      process_lm_results <- function(data, ...) {
        safelm = purrr::safely(.f = stats::lm)
        temp1 <- data[outliers == FALSE]
        temp2 <- temp1[, .(data = list(.SD)), by = responder
        ][, `:=`(safe_lm, purrr::map(data, function(df, ...) safelm(..., data = df), ...))
        ][, `:=`(safe_lm, purrr::map(safe_lm, function(x) x$result))
        ][, `:=`(error_msg, purrr::map_chr(safe_lm, function(x) if (is.null(x$error)) "" else x$error$message))
        ][, `:=`(warning_msg, purrr::map_chr(safe_lm, function(x) if (is.null(x$warning)) "" else x$warning$message))
        ][, `:=`(lm_predict, purrr::map2(safe_lm, warning_msg, function(x, w) if (w == "") stats::predict(x) else NA))
        ][, `:=`(lm_slope, purrr::map(safe_lm, function(x) coef(x)["seq_days"]))
        ][, `:=`(r_squared, purrr::map_dbl(safe_lm, function(x) if (!is.null(x)) summary(x)$r.squared else NA))]
        # Print message
        cat(crayon::white("\u2022 Check for errors and warnings in Simple Linear Regression\n"))
        check_errors_and_warnings(temp2)
        temp3 <- temp2[, c("responder", "lm_slope", "r_squared")][]
        final <- temp3 |> tidyfst::unnest_dt(lm_slope)
        return(final)
      }
      # 函数调用
      final <- tryCatch({
        if (!is.null(my_break)) {
          cut_data <- cut_weight(data = data, my_break = my_break, range_offset = range_offset)
          slopes_cut <- process_lm_results(data = cut_data, weight ~ seq_days)
          cat(crayon::green(paste0("\u2022 Calculate ADG at ", my_break[1], "~", my_break[2], "kg weight range using Simple Linear Regression succeeded!\n")))
          final <- merge(cut_data, slopes_cut, by = "responder")[, .(responder, location, stage, date, seq_in_location, seq_days, seq_in_day, weight, predict, r_squared, lm_slope, outliers)]

          temp_weight_get <- final[outliers == FALSE]
          temp_min_weight <- handle_data(data = temp_weight_get, seq_days, 1, "min_weight_cut")
          temp_max_weight <- handle_data(data = temp_weight_get, seq_days, -1, "max_weight_cut")
          info_temp_date <- data.table::copy(final)[, .(start_date_cut = min(date), end_date_cut = max(date)), by = responder]
          info_temp_base <- unique(final[, .(responder, stage, r_squared, lm_slope)])

          info_temp <- data.table::merge.data.table(info_temp_base, info_temp_date)
          weight_temp <- data.table::merge.data.table(temp_min_weight, temp_max_weight)
          temp_final <- data.table::merge.data.table(info_temp, weight_temp)
          temp_final <- temp_final[, stage_days := (my_break[2] * 1000 - my_break[1] * 1000) / lm_slope]
          temp_final <- temp_final[, .(responder, location, stage, start_date_cut, min_weight_cut, end_date_cut, max_weight_cut, r_squared, lm_slope, stage_days)]

          fin <- list(adg_info = temp_final, adg_data = final)

        } else {
          slopes <- process_lm_results(data = data, weight ~ seq_days)
          cat(crayon::green("\u2022 Calculate ADG using Simple Linear Regression succeeded!\n"))
          final <- merge(data, slopes, by = "responder")

          temp_weight_get <- final[outliers == FALSE]
          temp_min_weight <- handle_data(data = temp_weight_get, seq_days, 1, "min_weight_origin")
          temp_max_weight <- handle_data(data = temp_weight_get, seq_days, -1, "max_weight_origin")
          info_temp_date <- data.table::copy(final)[, .(start_date_origin = min(date), end_date_origin = max(date)), by = responder]
          info_temp_base <- unique(final[, .(responder, r_squared, lm_slope)])

          info_temp <- data.table::merge.data.table(info_temp_base, info_temp_date)
          weight_temp <- data.table::merge.data.table(temp_min_weight, temp_max_weight)
          temp_final <- data.table::merge.data.table(info_temp, weight_temp)
          temp_final <- temp_final[, .(responder, location, start_date_origin, min_weight_origin, end_date_origin, max_weight_origin, r_squared, lm_slope)]

          fin <- list(adg_info = temp_final, adg_data = final)
          #cat(green("\u2022 Calculate ADG using Simple Linear Regression succeeded\n"))
        }
      }, error = function(e) {
        cat(crayon::red("\u2022 Error: ", conditionMessage(e), "\n"))
        stop("Execution error, the program has stopped")
      })

      return(final)
    }
    #生成生长曲线
    create_plots <- function(data) {
      data <- data[, `:=`(color_judge, data.table::fifelse(outliers == F, "Normal", "Outlier"))
      ][, .(data = list(.SD)), location]

      data[, `:=`(plot, purrr::map2(data, location, function(.x, .y) {
        slopes_and_r_squared <- .x[, .(lm_slope = unique(lm_slope), r_squared = unique(r_squared)), by = responder]

        if (!is.null(my_break)) {
          slopes_and_r_squared[, day_diff := (my_break[2] * 1000 - my_break[1] * 1000) / lm_slope]
          slopes_and_r_squared[, day_text := sprintf("Slope: %.2f, R^2: %.2f\n%d~%d kg: %.1f days", lm_slope, r_squared, my_break[1], my_break[2], day_diff)]
        } else {
          slopes_and_r_squared[, day_text := sprintf("Slope: %.2f, R^2: %.2f", lm_slope, r_squared)]
        }

        ggplot2::ggplot(data = .x, ggplot2::aes(x = date, y = weight)) +
          ggplot2::theme_bw() +
          ggplot2::geom_point(ggplot2::aes(col = color_judge), size = 1, na.rm = T) +
          ggplot2::scale_color_manual(values = c(Normal = "#38b48b", Outlier = "#b81a35"), name = "robust regression") +
          ggplot2::scale_x_date(date_breaks = "2 day", date_labels = "%m-%d") +
          ggplot2::geom_line(ggplot2::aes(x = date, y = predict), na.rm = T) +
          ggplot2::facet_wrap( ~ as.numeric(responder), ncol = 2) +
          ggplot2::scale_y_continuous(breaks = seq(15000, 130000, 15000), limits = c(15000, 130000)) +
          ggplot2::labs(title = paste("Location:", .y)) +
          ggplot2::theme(legend.position = "bottom",
                         legend.title = ggplot2::element_text(size = 20),
                         legend.text = ggplot2::element_text(size = 20),
                         axis.text.x = ggplot2::element_text(angle = -90, size = 10),
                         plot.title = ggplot2::element_text(size = 25, face = "bold")
          ) +
          ggplot2::geom_hline(yintercept = 30000, linetype = "dashed", color = "#aed0ee") +
          ggplot2::geom_hline(yintercept = 60000, linetype = "dashed", color = "#aed0ee") +
          ggplot2::geom_hline(yintercept = 115000, linetype = "dashed", color = "#aed0ee") +
          ggplot2::geom_text(data = slopes_and_r_squared, mapping = ggplot2::aes(label = day_text, x = min(.x$date), y = 130000, group = responder), hjust = 0, vjust = 1, size = 3)
      }))]
      return(data)
    }
    #保存生长曲线
    save_plots <- function(data, save_path) {

      # Add argument checks
      if (!is.character(save_path) || length(save_path) != 1) {
        stop("Argument 'save_path' should be a single character string")
      }

      if (!dir.exists(save_path)) {
        stop(paste0("Directory '", save_path, "' does not exist"))
      }
      # 计算每个location中的responder数量和date天数
      location_dims <- data[, .(n_responders = data.table::uniqueN(data[[1]]$responder),
                                n_days = data.table::uniqueN(data[[1]]$date)), by = location]

      # 调整图像的宽度和高度
      adjusted_dims <- location_dims[, .(width = 0.5 * n_days, height = 5 * n_responders)]

      # 保存图像
      filename <- if (!is.null(my_break)) {
        weight_range <- paste0(my_break[1], "-", my_break[2])
        file.path(save_path, paste0("location_", data$location, "_", weight_range, "_growth.png"))
      } else {
        file.path(save_path, paste0("location_", data$location, "_growth.png"))
      }

      purrr::walk2(filename, data$plot, function(file, plot, width, height) {
        ggplot2::ggsave(filename = file, plot = plot, width = width, height = height, units = "cm", dpi = "retina")
      }, width = adjusted_dims$width, height = adjusted_dims$height)
    }

    #各模块运行
    temp1 <- process_data(data = data)
    temp2 <- clean_step1(data = temp1)
    temp3 <- clean_step2(data = temp2, threshold = threshold)
    temp4 <- clean_step3(data = temp3)
    temp5 <- clean_step4(data = temp4, my_break = my_break, range_offset = range_offset)

    if (!is.null(save_path)) {
      temp6 <- create_plots(data = temp5$adg_data)
      cat(crayon::green("\u2022 Printing growth curve images.Please wait a moment!\n"))
      save_plots(data = temp6, save_path = save_path)
    }
    return(temp5)
  }
  dfi_get <- function(data, my_break = my_break, adg_about) {

    process_data <- function(data) {
      if (missing(data)) stop("Missing data frame or data table!")
      if (!is.data.frame(data) && !inherits(data, "data.table")) stop("Data is not a data frame or data table!")

      # Check for required columns
      required_columns <- c("animal_number", "lifenumber", "responder", "location", "visit_time", "duration", "state", "weight", "feed_intake")
      missing_columns <- setdiff(required_columns, names(data))
      if (length(missing_columns) > 0) stop(paste("Missing columns:", paste(missing_columns, collapse = ", ")))

      # Check types for some columns
      if (!is.numeric(data$animal_number)) stop("'animal_number' must be numeric!")
      if (!is.logical(data$lifenumber) && !is.character(data$lifenumber)) stop("'lifenumber' must be logical or character!")
      if (!is.numeric(data$responder)) stop("'responder' must be numeric!")
      if (!is.numeric(data$location)) stop("'location' must be numeric!")
      if (!is.character(data$visit_time) && !inherits(data$visit_time, "POSIXt")) stop("'visit_time' must be character or POSIXct!")
      if (!is.numeric(data$duration)) stop("'duration' must be numeric!")
      if (!is.numeric(data$state)) stop("'state' must be numeric!")
      if (!is.numeric(data$weight)) stop("'weight' must be numeric!")
      if (!is.numeric(data$feed_intake)) stop("'feed_intake' must be numeric!")

      # Check if the data is a data.frame, if yes, then make a deep copy of the data and convert it into data.table
      if (is.data.frame(data)) data <- data.table::as.data.table(data.table::copy(data))

      # Filter out the data with NA in 'responder' column and remove duplicates
      data_temp <- unique(data)[!is.na(responder)]

      # Create a unique data.table for 'responder' and 'location'
      unique_dt <- unique(data_temp[, .(responder, location)])

      # Find duplicate 'responder's
      dup_responders <- unique_dt[, .N, by = .(responder)][N > 1]

      # Compute the number of records for each 'responder' and 'location'
      num_records <- unique(data_temp[, `:=`(n, .N), .(responder, location)][, .(responder, location, n)])

      # Set 'responder' as the key for join operations
      data.table::setkey(dup_responders, responder)
      data.table::setkey(num_records, responder)

      # Perform left join operation on 'num_records' and 'dup_responders'
      dup_records <- num_records[dup_responders]

      # Print duplicate 'responder's and their 'location's
      # if(nrow(dup_records) > 0) {
      #   cat(crayon::red("\u2022 There are", length(unique(dup_records$responder)), "duplicated responders.\n"))
      #   print(dup_records)
      # } else {
      #   cat(crayon::green("\u2022 There are no duplicate responders in different locations.\n"))
      # }

      # Modify the 'location' in the unique data.table for duplicate 'responder's
      if(nrow(dup_responders) > 0) {
        # Compute the 'location' with maximum number of records for each 'responder'
        max_n_location <- num_records[, .(max_n = max(n), location_maxn = location[which.max(n)]), by = responder]

        # Remove duplicates in 'max_n_location' after modifying 'location'
        max_n_location <- unique(max_n_location)

        # Perform left join operation on 'data_temp' and 'max_n_location' and update 'location' to 'location_maxn'
        data_temp <- merge(data_temp, max_n_location, by = "responder", all.x = TRUE)[, location := location_maxn][, c("max_n", "location_maxn") := NULL]
      }

      # Preprocess data and compute sequence features
      # Check the class of visit_time
      if(is.character(data_temp$visit_time)) {
        # If visit_time is a character vector, replace "/" with "-"
        data_temp[, visit_time := gsub("/", "-", visit_time)]
        data_pre <- data_temp[, `:=`(c("date", "time"), data.table::IDateTime(visit_time))]
      } else {
        # If visit_time is not a character vector, assume it's a datetime object
        data_pre <- data_temp[, `:=`(c("date", "time"), data.table::IDateTime(visit_time))]
      }
      data_pre <- data_pre[data.table::CJ(date = tidyr::full_seq(date, 1)), on = .(date)  # Compute complete sequence of dates
      ][order(date), `:=`(seq_days, .GRP), by = date  # Compute sequence number of days
      ][order(visit_time), `:=`(seq_in_day, 1:.N), by = .(responder, date)  # Compute sequence number in day
      ][order(visit_time), `:=`(seq_in_location, 1:.N), by = .(location, date)  # Compute sequence number in location
      ][order(responder, visit_time)  # Order data by 'responder' and 'visit_time'
      ][, .(responder, location, date, seq_in_location, seq_days, seq_in_day, duration, visit_time, feed_intake, weight)  # Keep only necessary columns
      ][, `:=` (responder = as.character(responder),  # Convert 'responder' and 'location' to character type
                location = as.character(location),
                weight = as.numeric(weight))][]  # Convert 'weight' to numeric type

      data_pre2 = split(data_pre, by = "location")
      data_pre3 = purrr::map(data_pre2, function(x) {
        temp = x[order(visit_time)][responder != 0 & !is.na(location)]
        data.table::setnames(temp, c("feed_intake", "duration", "visit_time"),
                             c("fiv", "otv", "entrancetime"))
        temp[, `:=`(entrancefeedweight = 0, exitfeedweight = 0,
                    exittime = entrancetime + lubridate::seconds(otv),
                    frv = fiv/(otv/60))][, `:=`(lwd = 0, fwd = 0,
                                                ltd = 0, ftd = 0)]
      })

      cat(crayon::green("\u2022 Successfully generated the following 7 variables during the food intake correction process.\n"))
      cat(crayon::green(" - FIV:feed intake per visit;\n"))
      cat(crayon::green(" - OTV:occupation time per visit;\n"))
      cat(crayon::green(" - FRV:feeding rate per visit;\n"))
      cat(crayon::red(" - LWD:leading weight difference;\n"))
      cat(crayon::red(" - LTD:leading time difference;\n"))
      cat(crayon::red(" - FWD:following weight difference;\n"))
      cat(crayon::red(" - FTD:following time difference.\n"))

      #适合nedap和fire, 此处仅仅针对nedap
      transformed_1 <- purrr::map(data_pre3, function(x) {
        x[, `:=`(
          fiv_lo = data.table::fifelse(fiv < -20, 1, 0),
          fiv_hi = data.table::fifelse(fiv >
                                         2000, 1, 0),
          fiv_0 = data.table::fifelse(otv == 0 & abs(fiv) >
                                        20, 1, 0),
          otv_lo = data.table::fifelse(otv < 0, 1, 0),
          otv_hi = data.table::fifelse(otv >
                                         3600, 1, 0),
          frv_hi_fiv_lo = data.table::fifelse(fiv > 0 & fiv <
                                                50 &
                                                frv > 500, 1, 0),
          frv_hi_strict = data.table::fifelse(fiv >=
                                                50 &
                                                any(
                                                  data.table::shift(fiv, type = "lag") < -20, data.table::shift(fiv,
                                                                                                                type = "lead") < -20
                                                ) & frv > 110, 1, 0),
          frv_hi = data.table::fifelse(fiv >=
                                         50 &
                                         any(
                                           data.table::shift(fiv, type = "lag", n = 2) < -20,
                                           data.table::shift(fiv,
                                                             type = "lead", n = 2) < -20
                                         ) & frv > 170, 1, 0),
          frv_0 = data.table::fifelse(frv == 0 &
                                        otv > 500, 1, 0),
          frv_lo = data.table::fifelse(frv !=
                                         0 &
                                         abs(frv) <= 2, 1, 0),
          lwd_lo = data.table::fifelse((!is.na(lwd)) &
                                         lwd < -20, 1, 0),
          lwd_hi = data.table::fifelse((!is.na(lwd)) &
                                         lwd > 1800, 1, 0),
          fwd_lo = data.table::fifelse((!is.na(fwd)) &
                                         fwd < -20, 1, 0),
          fwd_hi = data.table::fifelse((!is.na(fwd)) &
                                         fwd > 1800, 1, 0),
          ltd_lo = data.table::fifelse((!is.na(ltd)) &
                                         ltd < 0, 1, 0),
          ftd_lo = data.table::fifelse((!is.na(ftd)) &
                                         ftd < 0, 1, 0)
        )][, `:=`(date, lubridate::ymd(as.Date(date)))][order(entrancetime),
                                                        `:=`(seq_in_day, 1:.N), by = .(responder, date)][order(entrancetime),
                                                                                                         `:=`(seq_days, .GRP), by = date][order(responder,
                                                                                                                                                entrancetime)]
      })
      transformed_2 = data.table::rbindlist(transformed_1, use.names = T, fill = T)

      cat(crayon::green("\u2022 Successfully generated 16 error types from 7 variables:\n"))
      cat(crayon::green(" - FIV-lo; FIV-hi; FIV-0; OTV-lo; OTV-hi; FRV-hi-FIV-lo; FRV-hi-strict; FRV-hi; FRV-0; FRV-lo;\n"))
      cat(crayon::red(" - LWD-lo; LWD-hi; FWD-lo; FWD-hi; LTD-lo; FTD-lo.\n"))


      transformed_3 <- transformed_2[, .(date, seq_in_day, seq_days,
                                         location, responder, entrancetime, exittime, entrancefeedweight,
                                         exitfeedweight, weight, otv, fiv, frv, ltd, ftd, lwd,
                                         fwd, fiv_lo, fiv_hi, fiv_0, otv_lo, otv_hi, frv_hi_fiv_lo,
                                         frv_hi_strict, frv_hi, frv_0, frv_lo, lwd_lo, lwd_hi,
                                         fwd_lo, fwd_hi, ltd_lo, ftd_lo)]
      extract_feed_intake_order <- transformed_2[, .(responder, location, date, seq_in_location, seq_days, seq_in_day, fiv, weight)]

      final <- list(transformed_data = transformed_3, feedintake_order = extract_feed_intake_order)

      return(final)
    }

    dfi_correct <- function(data, my_break = my_break, adg_about = adg_about) {

      #col_names = names(origin_data)[c(1:5, 10:17, 18:33)]
      # cols_need = c("date", "seq_in_day", "seq_days", "location", "responder", "weight", "otv", "fiv", "frv",
      #               "ltd", "ftd", "lwd", "fwd", "fiv_lo", "fiv_hi", "fiv_0", "otv_lo", "otv_hi", "frv_hi_fiv_lo",
      #               "frv_hi_strict", "frv_hi", "frv_0", "frv_lo", "lwd_lo", "lwd_hi", "fwd_lo", "fwd_hi",
      #               "ltd_lo", "ftd_lo")
      #error_type = col_names[14:29]
      error_type = c("fiv_lo", "fiv_hi", "fiv_0", "otv_lo", "otv_hi", "frv_hi_fiv_lo", "frv_hi_strict", "frv_hi", "frv_0",
                     "frv_lo", "lwd_lo", "lwd_hi", "fwd_lo", "fwd_hi", "ltd_lo", "ftd_lo")

      temp_inner_join = data$transformed_data[, c("date", "seq_in_day", "seq_days", "location", "responder", "weight", "otv", "fiv", "frv", "ltd", "ftd", "lwd", "fwd", "fiv_lo", "fiv_hi", "fiv_0", "otv_lo", "otv_hi", "frv_hi_fiv_lo","frv_hi_strict", "frv_hi", "frv_0", "frv_lo", "lwd_lo", "lwd_hi", "fwd_lo", "fwd_hi", "ltd_lo", "ftd_lo")][, OE := apply(.SD, 1, function(x)sum(x, na.rm = T)), .SDcols = error_type][]

      origin_dfi = temp_inner_join[, .(origin_dfi = sum(fiv)), by = .(responder, seq_days)]

      right_dfi = temp_inner_join[OE == 0][, .(dfi_right_part = sum(fiv)), by = .(responder, seq_days)]
      error_dfi_data = temp_inner_join[OE != 0]
      error_dfi = temp_inner_join[OE != 0][, .(dfi_error_part = sum(fiv)), by = .(responder, seq_days)]


      otd_fid_trans <- function(data, name1, name2, name3, ...) {
        temp1 <- function(col_names, ...) {
          eval(as.name(data))[eval(as.name(col_names)) > 0, by = .(responder, seq_days), purrr::map(.SD, sum), .SDcols = name1]
        }
        temp2 <- purrr::map(name2, temp1)
        temp3 <-purrr::map2(temp2, name3, function(x, y) data.table::setnames(x, name1, y))

        # 使用R base函数merge代替tidyfst::full_join_dt
        temp4 <- Reduce(function(x, y) merge(x, y, by = c("responder", "seq_days"), all = TRUE), temp3)
        return(temp4)
      }

      useful_list <- data.table::data.table(
        data = c("error_dfi_data", "error_dfi_data"),
        name1 = c("otv", "fiv"),
        name2 = list(I(names(error_dfi_data)[c(14:15, 19:27)]), I(names(error_dfi_data)[c(17:18, 28:29)])),
        name3 = list(I(paste0("otd_", c(1:2, 6:14))), I(paste0("fid_", c(4:5, 15:16))))
      )

      # 使用base R函数mapply代替purrr::pmap
      temp5 = purrr::pmap(useful_list, otd_fid_trans)

      temp6 = Reduce(function(x, y) merge(x, y, by = c("responder", "seq_days"), all = TRUE), temp5)

      cols_error_types = names(temp_inner_join)[14:29]
      cols_error_types2 = paste0(cols_error_types, "_p")

      temp7 = temp_inner_join[, lapply(.SD, sum), .SDcols = cols_error_types, by = .(responder, seq_days)]

      temp8 = temp_inner_join[, .N, by = .(responder, seq_days)
      ][temp7, on = c("responder", "seq_days")
      ][, lapply(.SD, function(x) x / N), .SDcols = cols_error_types, by = .(responder, seq_days)]


      data.table::setnames(temp8, cols_error_types, cols_error_types2)
      #temp9 = temp6[temp8, on = c("responder", "seq_days")][adg, on = c("responder")][bw, on = c("responder", "seq_days")][error_dfi, on = c("responder", "seq_days")]
      temp9 = temp6[temp8, on = c("responder", "seq_days")][error_dfi, on = c("responder", "seq_days")]
      temp9[is.na(temp9)] <- 0


      right_dfi_in_one_day = temp9[right_dfi, on = .(responder, seq_days)][!is.na(dfi_error_part)][, dfi_error_part := NULL]
      right_dfi_each_day = temp9[right_dfi, on = .(responder, seq_days)][is.na(dfi_error_part)][, .(responder, seq_days, dfi_right_part)]

      base_info_adg = adg_about$adg_info[, .(responder, location, lm_slope)]
      base_info_weight = unique(adg_about$adg_data[, .(responder, seq_days, weight)][, weight := mean(weight, na.rm = TRUE), , by = .(responder, seq_days)])

      right_dfi_in_one_day_1 <- merge(right_dfi_in_one_day, base_info_adg, by = "responder", all.x = T)
      right_dfi_in_one_day_2 <- merge(right_dfi_in_one_day_1, base_info_weight, by = c("responder", "seq_days"), all.x = T)
      right_dfi_in_one_day_3 <- right_dfi_in_one_day_2[!is.na(right_dfi_in_one_day_2$weight), ]

      temp10 <- data.table::setDF(right_dfi_in_one_day_3) |> #right_dfi_in_one_day
        recipes::recipe(dfi_right_part ~ .) |>
        recipes::update_role(responder, seq_days, location, new_role = "id") |>
        recipes::step_corr(recipes::all_predictors()) |>
        recipes::step_zv(recipes::all_numeric()) |>
        recipes::step_scale(recipes::all_predictors()) |>
        recipes::prep() |>
        recipes::juice() |>
        dplyr::mutate_at("responder", as.factor)

      run_models <- function(data, equation1, equation2) {

        # 尝试运行第一个模型
        model <- tryCatch({
          formula_str <- paste0(crayon::green("\u2022 Running model with equation: \n"), gsub("\\s+", " ", paste(deparse(equation1), collapse = "")))
          cat(formula_str,"\n")
          lme4::lmer(equation1, data = data)
        },
        error = function(e) {
          # 如果第一个模型报错，运行第二个模型
          formula_str <- paste0(crayon::green("\u2022 Running model with equation: \n"), gsub("\\s+", " ", paste(deparse(equation2), collapse = "")))
          cat(formula_str,"\n")
          lme4::lmer(equation2, data = data)
        })

        # 返回模型结果
        return(model)
      }
      all_name <- names(temp10)
      predictor_name1 <- names(temp10)[!all_name %in% c("responder", "dfi_right_part", "seq_days")]
      predictor_name2 <- names(temp10)[!all_name %in% c("responder", "dfi_right_part", "seq_days", "location", "lm_slope", "weight")]
      temp11 <- temp10 |> tibble::rownames_to_column(var = "rownames")

      model_formula1 <- stats::as.formula(paste0("dfi_right_part ~ ", paste0(predictor_name1, collapse = "+"), " + (1 | responder)", collapse = ""))
      model_formula2 <- stats::as.formula(paste0("dfi_right_part ~ ", paste0(predictor_name2, collapse = "+"), " + (1 | responder)", collapse = ""))

      mod <- run_models(data = temp10, equation1 = model_formula1, equation2 = model_formula2)

      temp12 <- broom.mixed::augment(mod) |> janitor::clean_names()

      if (nrow(temp12) == nrow(temp11) &
          (!c("rownames") %in% names(temp12))) {
        temp14 <- temp12 |> dplyr::bind_cols(temp10[, 2])
      } else if (nrow(temp12) != nrow(temp11) &
                 (c("rownames") %in% names(temp12))) {
        temp14 <- temp12 |>
          tidyfst::inner_join_dt(temp11, by = c("rownames", "dfi_right_part"))
      }

      # 将"responder"列变为因子
      #error_dfi[, responder := as.factor(responder)]
      error_dfi <- merge(temp14, error_dfi, all.x = TRUE) #error_dfi = temp15

      temp16 <- error_dfi[,c("responder", "seq_days", "fitted")]
      data.table::setnames(temp16, "fitted", "dfi_right_part")
      temp17 <- data.table::rbindlist(list(temp16, right_dfi_each_day))[order(responder, seq_days)]


      base_info_origin = unique(data$feedintake_order[, .(responder, location, date, seq_days)]) #adg_info=NULL

      if (!is.null(my_break)) {
        base_info_stage = unique(adg_about$adg_data[, .(responder, location, stage, date, seq_days)]) #从日增重数据结果中获取 #adg_info!=NULL时
        temp18 <- merge(temp17, base_info_stage, all = FALSE)
      } else {
        temp18 <- merge(temp17, base_info_origin, all = FALSE)
      }

      data.table::setnames(temp18, "dfi_right_part", "corrected_dfi")
      temp19 <- merge(temp18, origin_dfi, all = FALSE)

      if (!is.null(my_break)) {
        temp20 <- temp19[, c("responder", "location", "stage", "date", "seq_days", "origin_dfi", "corrected_dfi")]
      } else {
        temp20 <- temp19[, c("responder", "location", "date", "seq_days", "origin_dfi", "corrected_dfi")]
      }

      fin1 <- temp20[, lapply(.SD, mean, na.rm = TRUE), .SDcols = c("origin_dfi", "corrected_dfi"), by = .(responder, location)]

      fin2 <- temp20[, .(test_days = max(seq_days, na.rm = TRUE)), by = .(responder, location)]

      fin3 <- merge(fin2, fin1, all.x = T)

      fin <- list(dfi_info = fin3, dfi_data = temp20, feedintake_order = data$feedintake_order)
      return(fin)

    }

    data_temp <- process_data(data)
    dfi_temp <- dfi_correct(data = data_temp, my_break = my_break, adg_about = adg_about)

  }
  fcr_get <- function(adg_res, dfi_res, my_break = NULL) {

    dt1 <- adg_res$adg_info
    dt2 <- dfi_res$dfi_info
    # Set keys
    data.table::setkey(dt1, responder, location)
    data.table::setkey(dt2, responder, location)

    # Perform an inner join

    if (!is.null(my_break)) {
      inner_join_dt <- dt1[dt2, nomatch = 0]
      dt3 <- inner_join_dt[, fcr := corrected_dfi/lm_slope
      ][, cor_fcr := fcr + (my_break[1] - min_weight_cut/1000) * 0.005 + (my_break[2] - max_weight_cut/1000) * 0.005][]
    } else {
      inner_join_dt <- dt1[dt2, nomatch = 0]
      dt3 <- inner_join_dt[, fcr := corrected_dfi/lm_slope][]
    }
    return(dt3)
  }
  #caculate
  adg_res <- adg_get(data, my_break = my_break, range_offset = range_offset, threshold = threshold, save_path = save_path)
  dfi_res <- dfi_get(data, my_break = my_break, adg_about = adg_res)
  fcr_res <- fcr_get(adg_res = adg_res, dfi_res = dfi_res, my_break = my_break)

  res <- list(fcr_res, adg_res$adg_info, adg_res$adg_data, dfi_res$dfi_info, dfi_res$dfi_data, dfi_res$feedintake_order)

  return(res)
}
