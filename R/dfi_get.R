# WARNING - Generated by {fusen} from /dev/flat_teaching.Rmd: do not edit by hand

#' ADFI get from pig performance test station csv data
#' 
#' @param data A data frame or data table containing the nedap or fire pig performance test data to be processed. Columns must include 'visit_time', 'location', 'responder', 'feed_intake'.
#' @param my_break Optional, a numeric vector of length 2, indicates target weight range for calculating DFI, default NULL. If not NULL, DFI will be calculated within this range.
#' @param adg_about ADG results from function of adg_get().
#'
#' @return A list containing:
#' - dfi_info: A data.table containing DFI statistics
#' - dfi_data: A data.table containing processed sample data
#' - feedintake_order: A data.table containing dfi order data
#' 
#' @export
#' @examples
#' data <- rio::import("C:/Users/Dell/Downloads/ppt_test_data.xlsx")
#' adg_res <- adg_get(data = data)
#' dfi_get <- dfi_get(data = data, adg_about = adg_res)
dfi_get <- function(data, my_break = NULL, adg_about) {
    . <- ..col_names <- .GRP <- .N <- N <- OE <- dfi_error_part <- dfi_right_part <- duration <- 
    entrancefeedweight <- entrancetime <- exitfeedweight <- exittime <- feed_intake <- fiv <- 
    fiv_0  <- fiv_hi <- fiv_lo <- frv <- frv_0 <- frv_hi <- frv_hi_fiv_lo <- frv_hi_strict <- 
      frv_lo <- ftd <- ftd_lo <- fwd <- fwd_hi <- fwd_lo <- lm_slope <- location <- location_maxn <- 
      ltd <- ltd_lo <- lwd <- lwd_hi <- lwd_lo <- n <- otv <- otv_hi <- otv_lo <- responder <- seq_days <- 
      seq_in_day <- seq_in_location <- stage <- visit_time <- weight <- cols_need <- ..cols_need <- NULL
    
    process_data <- function(data) {
      if (missing(data)) stop("Missing data frame or data table!")
      if (!is.data.frame(data) && !inherits(data, "data.table")) stop("Data is not a data frame or data table!")

      # Check for required columns
      required_columns <- c("animal_number", "lifenumber", "responder", "location", "visit_time", "duration", "state", "weight", "feed_intake")
      missing_columns <- setdiff(required_columns, names(data))
      if (length(missing_columns) > 0) stop(paste("Missing columns:", paste(missing_columns, collapse = ", ")))

      # Check types for some columns
      if (!is.numeric(data$animal_number)) stop("'animal_number' must be numeric!")
      if (!is.logical(data$lifenumber) && !is.character(data$lifenumber)) stop("'lifenumber' must be logical or character!")
      if (!is.numeric(data$responder)) stop("'responder' must be numeric!")
      if (!is.numeric(data$location)) stop("'location' must be numeric!")
      if (!is.character(data$visit_time) && !inherits(data$visit_time, "POSIXt")) stop("'visit_time' must be character or POSIXct!")
      if (!is.numeric(data$duration)) stop("'duration' must be numeric!")
      if (!is.numeric(data$state)) stop("'state' must be numeric!")
      if (!is.numeric(data$weight)) stop("'weight' must be numeric!")
      if (!is.numeric(data$feed_intake)) stop("'feed_intake' must be numeric!")

      # Check if the data is a data.frame, if yes, then make a deep copy of the data and convert it into data.table
      if (is.data.frame(data)) data <- data.table::as.data.table(data.table::copy(data))

      # Filter out the data with NA in 'responder' column and remove duplicates
      data_temp <- unique(data)[!is.na(responder)]

      # Create a unique data.table for 'responder' and 'location'
      unique_dt <- unique(data_temp[, .(responder, location)])

      # Find duplicate 'responder's
      dup_responders <- unique_dt[, .N, by = .(responder)][N > 1]

      # Compute the number of records for each 'responder' and 'location'
      num_records <- unique(data_temp[, `:=`(n, .N), .(responder, location)][, .(responder, location, n)])

      # Set 'responder' as the key for join operations
      data.table::setkey(dup_responders, responder)
      data.table::setkey(num_records, responder)

      # Perform left join operation on 'num_records' and 'dup_responders'
      dup_records <- num_records[dup_responders]

      #Print duplicate 'responder's and their 'location's
      if(nrow(dup_records) > 0) {
        cat(crayon::red("\u2022 There are", length(unique(dup_records$responder)), "duplicated responders.\n"))
        print(dup_records)
      } else {
        cat(crayon::green("\u2022 There are no duplicate responders in different locations.\n"))
      }

      # Modify the 'location' in the unique data.table for duplicate 'responder's
      if(nrow(dup_responders) > 0) {
        # Compute the 'location' with maximum number of records for each 'responder'
        max_n_location <- num_records[, .(max_n = max(n), location_maxn = location[which.max(n)]), by = responder]

        # Remove duplicates in 'max_n_location' after modifying 'location'
        max_n_location <- unique(max_n_location)

        # Perform left join operation on 'data_temp' and 'max_n_location' and update 'location' to 'location_maxn'
        data_temp <- merge(data_temp, max_n_location, by = "responder", all.x = TRUE)[, location := location_maxn][, c("max_n", "location_maxn") := NULL]
      }

      # Preprocess data and compute sequence features
      # Check the class of visit_time
      if(is.character(data_temp$visit_time)) {
        # If visit_time is a character vector, replace "/" with "-"
        data_temp[, visit_time := gsub("/", "-", visit_time)]
        data_pre <- data_temp[, `:=`(c("date", "time"), data.table::IDateTime(visit_time))]
      } else {
        # If visit_time is not a character vector, assume it's a datetime object
        data_pre <- data_temp[, `:=`(c("date", "time"), data.table::IDateTime(visit_time))]
      }
      data_pre <- data_pre[data.table::CJ(date = tidyr::full_seq(date, 1)), on = .(date)  # Compute complete sequence of dates
      ][order(date), `:=`(seq_days, .GRP), by = date  # Compute sequence number of days
      ][order(visit_time), `:=`(seq_in_day, 1:.N), by = .(responder, date)  # Compute sequence number in day
      ][order(visit_time), `:=`(seq_in_location, 1:.N), by = .(location, date)  # Compute sequence number in location
      ][order(responder, visit_time)  # Order data by 'responder' and 'visit_time'
      ][, .(responder, location, date, seq_in_location, seq_days, seq_in_day, duration, visit_time, feed_intake, weight)  # Keep only necessary columns
      ][, `:=` (responder = as.character(responder),  # Convert 'responder' and 'location' to character type
                location = as.character(location),
                weight = as.numeric(weight))][]  # Convert 'weight' to numeric type

      data_pre2 = split(data_pre, by = "location")
      data_pre3 = purrr::map(data_pre2, function(x) {
        temp = x[order(visit_time)][responder != 0 & !is.na(location)]
        data.table::setnames(temp, c("feed_intake", "duration", "visit_time"),
                             c("fiv", "otv", "entrancetime"))
        temp[, `:=`(entrancefeedweight = 0, exitfeedweight = 0,
                    exittime = entrancetime + lubridate::seconds(otv),
                    frv = fiv/(otv/60))][, `:=`(lwd = 0, fwd = 0,
                                                ltd = 0, ftd = 0)]
      })

      cat(crayon::green("\u2022 Successfully generated the following 7 variables during the food intake correction process.\n"))
      cat(crayon::green(" - FIV:feed intake per visit;\n"))
      cat(crayon::green(" - OTV:occupation time per visit;\n"))
      cat(crayon::green(" - FRV:feeding rate per visit;\n"))
      cat(crayon::red(" - LWD:leading weight difference;\n"))
      cat(crayon::red(" - LTD:leading time difference;\n"))
      cat(crayon::red(" - FWD:following weight difference;\n"))
      cat(crayon::red(" - FTD:following time difference.\n"))

      #适合nedap和fire, 此处仅仅针对nedap
      transformed_1 <- purrr::map(data_pre3, function(x) {
        x[, `:=`(
          fiv_lo = data.table::fifelse(fiv < -20, 1, 0),
          fiv_hi = data.table::fifelse(fiv >
                                         2000, 1, 0),
          fiv_0 = data.table::fifelse(otv == 0 & abs(fiv) >
                                        20, 1, 0),
          otv_lo = data.table::fifelse(otv < 0, 1, 0),
          otv_hi = data.table::fifelse(otv >
                                         3600, 1, 0),
          frv_hi_fiv_lo = data.table::fifelse(fiv > 0 & fiv <
                                                50 &
                                                frv > 500, 1, 0),
          frv_hi_strict = data.table::fifelse(fiv >=
                                                50 &
                                                any(
                                                  data.table::shift(fiv, type = "lag") < -20, data.table::shift(fiv,
                                                                                                                type = "lead") < -20
                                                ) & frv > 110, 1, 0),
          frv_hi = data.table::fifelse(fiv >=
                                         50 &
                                         any(
                                           data.table::shift(fiv, type = "lag", n = 2) < -20,
                                           data.table::shift(fiv,
                                                             type = "lead", n = 2) < -20
                                         ) & frv > 170, 1, 0),
          frv_0 = data.table::fifelse(frv == 0 &
                                        otv > 500, 1, 0),
          frv_lo = data.table::fifelse(frv !=
                                         0 &
                                         abs(frv) <= 2, 1, 0),
          lwd_lo = data.table::fifelse((!is.na(lwd)) &
                                         lwd < -20, 1, 0),
          lwd_hi = data.table::fifelse((!is.na(lwd)) &
                                         lwd > 1800, 1, 0),
          fwd_lo = data.table::fifelse((!is.na(fwd)) &
                                         fwd < -20, 1, 0),
          fwd_hi = data.table::fifelse((!is.na(fwd)) &
                                         fwd > 1800, 1, 0),
          ltd_lo = data.table::fifelse((!is.na(ltd)) &
                                         ltd < 0, 1, 0),
          ftd_lo = data.table::fifelse((!is.na(ftd)) &
                                         ftd < 0, 1, 0)
        )][, `:=`(date, lubridate::ymd(as.Date(date)))][order(entrancetime),
                                                        `:=`(seq_in_day, 1:.N), by = .(responder, date)][order(entrancetime),
                                                                                                         `:=`(seq_days, .GRP), by = date][order(responder,
                                                                                                                                                entrancetime)]
      })
      transformed_2 = data.table::rbindlist(transformed_1, use.names = T, fill = T)

      cat(crayon::green("\u2022 Successfully generated 16 error types from 7 variables:\n"))
      cat(crayon::green(" - FIV-lo; FIV-hi; FIV-0; OTV-lo; OTV-hi; FRV-hi-FIV-lo; FRV-hi-strict; FRV-hi; FRV-0; FRV-lo;\n"))
      cat(crayon::red(" - LWD-lo; LWD-hi; FWD-lo; FWD-hi; LTD-lo; FTD-lo.\n"))


      transformed_3 <- transformed_2[, .(date, seq_in_day, seq_days,
                                         location, responder, entrancetime, exittime, entrancefeedweight,
                                         exitfeedweight, weight, otv, fiv, frv, ltd, ftd, lwd,
                                         fwd, fiv_lo, fiv_hi, fiv_0, otv_lo, otv_hi, frv_hi_fiv_lo,
                                         frv_hi_strict, frv_hi, frv_0, frv_lo, lwd_lo, lwd_hi,
                                         fwd_lo, fwd_hi, ltd_lo, ftd_lo)]
      extract_feed_intake_order <- transformed_2[, .(responder, location, date, seq_in_location, seq_days, seq_in_day, fiv, weight)]

      final <- list(transformed_data = transformed_3, feedintake_order = extract_feed_intake_order)

      return(final)
    }
    dfi_correct <- function(data, my_break = my_break, adg_about = adg_about) {

      #col_names = names(origin_data)[c(1:5, 10:17, 18:33)]
      cols_need = c("date", "seq_in_day", "seq_days", "location", "responder", "weight", "otv", "fiv", "frv",
                    "ltd", "ftd", "lwd", "fwd", "fiv_lo", "fiv_hi", "fiv_0", "otv_lo", "otv_hi", "frv_hi_fiv_lo",
                    "frv_hi_strict", "frv_hi", "frv_0", "frv_lo", "lwd_lo", "lwd_hi", "fwd_lo", "fwd_hi",
                    "ltd_lo", "ftd_lo")
      #error_type = col_names[14:29]
      error_type = c("fiv_lo", "fiv_hi", "fiv_0", "otv_lo", "otv_hi", "frv_hi_fiv_lo", "frv_hi_strict", "frv_hi", "frv_0",
                     "frv_lo", "lwd_lo", "lwd_hi", "fwd_lo", "fwd_hi", "ltd_lo", "ftd_lo")

      temp_inner_join = data$transformed_data[, ..cols_need][, OE := apply(.SD, 1, function(x)sum(x, na.rm = T)), .SDcols = error_type][]

      origin_dfi = temp_inner_join[, .(origin_dfi = sum(fiv)), by = .(responder, seq_days)]

      right_dfi = temp_inner_join[OE == 0][, .(dfi_right_part = sum(fiv)), by = .(responder, seq_days)]
      error_dfi_data = temp_inner_join[OE != 0]
      error_dfi = temp_inner_join[OE != 0][, .(dfi_error_part = sum(fiv)), by = .(responder, seq_days)]


      otd_fid_trans <- function(data, name1, name2, name3, ...) {
        temp1 <- function(col_names, ...) {
          eval(as.name(data))[eval(as.name(col_names)) > 0, by = .(responder, seq_days), purrr::map(.SD, sum), .SDcols = name1]
        }
        temp2 <- purrr::map(name2, temp1)
        temp3 <-purrr::map2(temp2, name3, function(x, y) data.table::setnames(x, name1, y))

        # 使用R base函数merge代替tidyfst::full_join_dt
        temp4 <- Reduce(function(x, y) merge(x, y, by = c("responder", "seq_days"), all = TRUE), temp3)
        return(temp4)
      }

      useful_list <- data.table::data.table(
        data = c("error_dfi_data", "error_dfi_data"),
        name1 = c("otv", "fiv"),
        name2 = list(I(names(error_dfi_data)[c(14:15, 19:27)]), I(names(error_dfi_data)[c(17:18, 28:29)])),
        name3 = list(I(paste0("otd_", c(1:2, 6:14))), I(paste0("fid_", c(4:5, 15:16))))
      )

      # 使用base R函数mapply代替purrr::pmap
      temp5 = purrr::pmap(useful_list, otd_fid_trans)

      temp6 = Reduce(function(x, y) merge(x, y, by = c("responder", "seq_days"), all = TRUE), temp5)

      cols_error_types = names(temp_inner_join)[14:29]
      cols_error_types2 = paste0(cols_error_types, "_p")

      temp7 = temp_inner_join[, lapply(.SD, sum), .SDcols = cols_error_types, by = .(responder, seq_days)]

      temp8 = temp_inner_join[, .N, by = .(responder, seq_days)
      ][temp7, on = c("responder", "seq_days")
      ][, lapply(.SD, function(x) x / N), .SDcols = cols_error_types, by = .(responder, seq_days)]


      data.table::setnames(temp8, cols_error_types, cols_error_types2)
      #temp9 = temp6[temp8, on = c("responder", "seq_days")][adg, on = c("responder")][bw, on = c("responder", "seq_days")][error_dfi, on = c("responder", "seq_days")]
      temp9 = temp6[temp8, on = c("responder", "seq_days")][error_dfi, on = c("responder", "seq_days")]
      temp9[is.na(temp9)] <- 0


      right_dfi_in_one_day = temp9[right_dfi, on = .(responder, seq_days)][!is.na(dfi_error_part)][, dfi_error_part := NULL]
      right_dfi_each_day = temp9[right_dfi, on = .(responder, seq_days)][is.na(dfi_error_part)][, .(responder, seq_days, dfi_right_part)]

      base_info_adg = adg_about$adg_info[, .(responder, location, lm_slope)]
      base_info_weight = unique(adg_about$adg_data[, .(responder, seq_days, weight)][, weight := mean(weight, na.rm = TRUE), , by = .(responder, seq_days)])

      right_dfi_in_one_day_1 <- merge(right_dfi_in_one_day, base_info_adg, by = "responder", all.x = T)
      right_dfi_in_one_day_2 <- merge(right_dfi_in_one_day_1, base_info_weight, by = c("responder", "seq_days"), all.x = T)
      right_dfi_in_one_day_3 <- right_dfi_in_one_day_2[!is.na(right_dfi_in_one_day_2$weight), ]

      temp10 <- data.table::setDF(right_dfi_in_one_day_3) |> #right_dfi_in_one_day
        recipes::recipe(dfi_right_part ~ .) |>
        recipes::update_role(responder, seq_days, location, new_role = "id") |>
        recipes::step_corr(recipes::all_predictors()) |>
        recipes::step_zv(recipes::all_numeric()) |>
        recipes::step_scale(recipes::all_predictors()) |>
        recipes::prep() |>
        recipes::juice() |>
        dplyr::mutate_at("responder", as.factor)

      run_models <- function(data, equation1, equation2) {

        # 尝试运行第一个模型
        model <- tryCatch({
          formula_str <- paste0(crayon::green("\u2022 Running model with equation: \n"), gsub("\\s+", " ", paste(deparse(equation1), collapse = "")))
          cat(formula_str,"\n")
          lme4::lmer(equation1, data = data)
        },
        error = function(e) {
          # 如果第一个模型报错，运行第二个模型
          formula_str <- paste0(crayon::green("\u2022 Running model with equation: \n"), gsub("\\s+", " ", paste(deparse(equation2), collapse = "")))
          cat(formula_str,"\n")
          lme4::lmer(equation2, data = data)
        })

        # 返回模型结果
        return(model)
      }
      all_name <- names(temp10)
      predictor_name1 <- names(temp10)[!all_name %in% c("responder", "dfi_right_part", "seq_days")]
      predictor_name2 <- names(temp10)[!all_name %in% c("responder", "dfi_right_part", "seq_days", "location", "lm_slope", "weight")]
      temp11 <- temp10 |> tibble::rownames_to_column(var = "rownames")

      model_formula1 <- stats::as.formula(paste0("dfi_right_part ~ ", paste0(predictor_name1, collapse = "+"), " + (1 | responder)", collapse = ""))
      model_formula2 <- stats::as.formula(paste0("dfi_right_part ~ ", paste0(predictor_name2, collapse = "+"), " + (1 | responder)", collapse = ""))

      mod <- run_models(data = temp10, equation1 = model_formula1, equation2 = model_formula2)

      temp12 <- broom.mixed::augment(mod) |> janitor::clean_names()

      if (nrow(temp12) == nrow(temp11) &
          (!c("rownames") %in% names(temp12))) {
        temp14 <- temp12 |> dplyr::bind_cols(temp10[, 2])
      } else if (nrow(temp12) != nrow(temp11) &
                 (c("rownames") %in% names(temp12))) {
        temp14 <- temp12 |>
          tidyfst::inner_join_dt(temp11, by = c("rownames", "dfi_right_part"))
      }

      # 将"responder"列变为因子
      #error_dfi[, responder := as.factor(responder)]
      error_dfi <- merge(temp14, error_dfi, all.x = TRUE) #error_dfi = temp15

      temp16 <- error_dfi[,c("responder", "seq_days", "fitted")]
      data.table::setnames(temp16, "fitted", "dfi_right_part")
      temp17 <- data.table::rbindlist(list(temp16, right_dfi_each_day))[order(responder, seq_days)]


      base_info_origin = unique(data$feedintake_order[, .(responder, location, date, seq_days)]) #adg_info=NULL

      if (!is.null(my_break)) {
        base_info_stage = unique(adg_about$adg_data[, .(responder, location, stage, date, seq_days)]) #从日增重数据结果中获取 #adg_info!=NULL时
        temp18 <- merge(temp17, base_info_stage, all = FALSE)
      } else {
        temp18 <- merge(temp17, base_info_origin, all = FALSE)
      }

      data.table::setnames(temp18, "dfi_right_part", "corrected_dfi")
      temp19 <- merge(temp18, origin_dfi, all = FALSE)

      if (!is.null(my_break)) {
        temp20 <- temp19[, c("responder", "location", "stage", "date", "seq_days", "origin_dfi", "corrected_dfi")]
      } else {
        temp20 <- temp19[, c("responder", "location", "date", "seq_days", "origin_dfi", "corrected_dfi")]
      }

      fin1 <- temp20[, lapply(.SD, mean, na.rm = TRUE), .SDcols = c("origin_dfi", "corrected_dfi"), by = .(responder, location)]

      fin2 <- temp20[, .(test_days = max(seq_days, na.rm = TRUE)), by = .(responder, location)]

      fin3 <- merge(fin2, fin1, all.x = T)

      fin <- list(dfi_info = fin3, dfi_data = temp20, feedintake_order = data$feedintake_order)
      return(fin)

    }

    data_temp <- process_data(data)
    dfi_temp <- dfi_correct(data = data_temp, my_break = my_break, adg_about = adg_about)

  }
