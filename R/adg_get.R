# WARNING - Generated by {fusen} from dev/flat_teaching.Rmd: do not edit by hand

#' ADG get from pig performance test station csv data
#' 
#' @param data A data frame or data table containing the nedap or fire pig performance test data to be processed. Columns must include 'visit_time', 'location', 'responder', 'feed_intake'.
#' @param my_break Optional, a numeric vector of length 2, indicates target weight range for calculating ADG, default NULL. If not NULL, ADG will be calculated within this range.
#' @param range_offset Optional, a numeric value, default 0.5. 
#' Used to extend the target weight range specified in my_break to avoid border effect.
#' For example, if my_break is c(60,90) and range_offset is 0.5, the actual range for analysis will be 57.5~92.5.
#' @param threshold Optional, a numeric value, default 1, used as the threshold to identify outliers in RANSAC regression, usually 0~2.
#' @param save_path Optional, a character string specifying where to save the generated growth curve images. If not NULL, images will be saved to this path.
#' @return A list containing:
#' - adg_info: A data.table containing ADG statistics
#' - adg_data: A data.table containing processed sample data
#' @importFrom stats "coef" "predict" "residuals" "sd"
#' @importFrom data.table ":=" ".SD" ".GRP" ".N"
#' 
#' @export
#' @examples
#' nedap_csv_data <- mintyr::nedap
#' adg_results <- adg_get(data = nedap_csv_data)
#' head(adg_results$adg_info)

# get adg results and create plots
adg_get <- function(data, my_break = NULL, range_offset = 0.5, threshold = 1, save_path = NULL) {
  # parameters check
  validate_arguments(threshold, my_break, range_offset)
  
  # get adg results
  adg_results <- process_adg_data(data) |> 
    clean_and_filter_weight_data() |> 
    remove_outliers_using_ransac(threshold) |> 
    validate_responder_weights() |> 
    calculate_adg_and_clean_data(my_break = my_break , range_offset)
  
  # save adg plots
  if (!is.null(save_path)) {
    create_adg_plots <- create_adg_plots(data = adg_results$adg_data, my_break = my_break)
    message(crayon::cyan("\u2022 Printing growth curve images.Please wait a moment!"))
    save_adg_plots(data = create_adg_plots, my_break = my_break, save_path = save_path)
  }
  
  return(adg_results)
}
# process adg data
process_adg_data <- function(data) {
  if (missing(data)) stop("Missing data frame or data table!")

  # Ensure the input is a data.table and create a deep copy
  if (!data.table::is.data.table(data)) {
    data <- data.table::as.data.table(data, keep.rownames = FALSE)
  } else {
    data <- data.table::copy(data)
  }

  # Define and check required columns
  nedap_cols <- c("animal_number", "lifenumber", "responder", "location", "visit_time", "duration", "state", "weight", "feed_intake")
  missing_columns <- setdiff(nedap_cols, names(data))
  if (length(missing_columns) > 0) stop(paste("Missing columns:", paste(missing_columns, collapse = ", ")))

  # Convert columns to appropriate types
  data[, `:=`(
    location = as.character(location),
    responder = as.character(responder),
    visit_time = if (!inherits(visit_time, c("POSIXct", "POSIXlt"))) {
      warning("visit_time converted to POSIXct. Please check if the data source is consistent.")
      as.POSIXct(visit_time, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
    } else visit_time,
    date = as.Date(visit_time)
  )]

  # Remove duplicates and filter out rows where responder is NA
  data <- unique(data[!is.na(responder)])

  # Identify duplicate responders across locations
  unique_dt <- unique(data[, .(responder, location)])
  dup_responders <- unique_dt[, .N, by = .(responder)][N > 1]

  # Count records for each responder-location combination
  num_records <- unique(data[, `:=`(n, .N), .(responder, location)][, .(responder, location, n)])

  # Set 'responder' as the key for join operations
  data.table::setkey(dup_responders, responder)
  data.table::setkey(num_records, responder)

  # Perform left join operation on 'num_records' and 'dup_responders'
  dup_records <- num_records[dup_responders]

  # Print duplicate 'responder's and their 'location's
  if(nrow(dup_responders) > 0) {
    message(crayon::red("\u2022 There are", nrow(dup_responders), "duplicated responders."))
    print(dup_records)
  } else {
    message(crayon::cyan("\u2022 There are no duplicate responders in different locations."))
  }

  # Handle duplicate responders by assigning them to the location with most records
  if (nrow(dup_responders) > 0) {
    max_n_location <- num_records[, .(max_n = max(n), location_maxn = location[which.max(n)]), by = responder]
    max_n_location <- unique(max_n_location)
    data <- merge(data, max_n_location, by = "responder", all.x = TRUE)[, `:=`(location, location_maxn)][, `:=`(c("max_n", "location_maxn"), NULL)]
  }

  # Create the final dataset with additional columns
  # Create the final dataset with additional columns
  data_pre <- data[data.table::CJ(date = tidyr::full_seq(date, 1)), on = .(date)
  ][, `:=`(seq_days, .GRP), by = .(date)
  ][order(visit_time), `:=`(seq_in_day, 1:.N), by = .(responder, date)
  ][order(visit_time), `:=`(seq_in_location, 1:.N), by = .(location, date)
  ][order(responder, visit_time)][]

  return(data_pre)
}
# remove weight < 15kg , test date range < 35days and records < 20
clean_and_filter_weight_data <- function(data) {
  # Set key for faster operations on responder
  data.table::setkey(data, responder)

  # Calculate the maximum weight for each responder
  max_weights <- data[, .(max_weight = max(weight, na.rm = TRUE)), by = responder]

  # Find responders whose all weights are less than 15000
  responder_to_delete <- max_weights[max_weight < 15000, responder]

  # Print the number of responders to be deleted due to low weight
  if(length(responder_to_delete) > 0){
    message(crayon::red("\u2022 Removing weight < 15kg records will delete responders: ", length(responder_to_delete)))
  } else {
    message(crayon::cyan("\u2022 The removing of weight < 15kg will not delete responder."))
  }

  # Filter and process data
  temp <- data[!responder %in% responder_to_delete,
               `:=`(
                 n = .N,  # Count of records for each responder and location
                 date_na = sum(is.na(weight)),  # Count of NA weights
                 date_length = as.integer(difftime(max(date), min(date), units = "days"))  # Date range in days
               ),
               by = .(responder, location)
  ][, `:=`(
    test_days_less_than_40 = date_length < 35,  # Test if date range is less than 35 days
    test_records_less_than_20 = n < 20,  # Test if number of records is less than 20
    data_na_greater_than_one_third = ifelse(date_length == 0, FALSE, date_na/date_length >= 1/3)  # Test if more than 1/3 of data is NA
  )]

  # Calculate row_sum and find outliers
  temp[, row_sum := test_days_less_than_40 + test_records_less_than_20 + data_na_greater_than_one_third]
  outlier <- unique(temp[row_sum > 0, .(responder, location, date_na, test_days_less_than_40, test_records_less_than_20, data_na_greater_than_one_third, row_sum)])

  # Final result: keep rows with row_sum == 0 and weight >= 15000
  step1_res <- temp[row_sum == 0 & weight >= 15000, .(responder, location, date, seq_in_location, seq_days, seq_in_day, weight)]

  # Print information about outliers
  if(nrow(outlier) > 0){
    message(crayon::red("\u2022 Removing records of missing will delete responders:", nrow(outlier)))
  } else {
    message(crayon::cyan("\u2022 No responder is deleted due to missing records."))
  }

  # Combine all deleted responders and print
  deleted_responders <- c(responder_to_delete, outlier$responder)
  message(crayon::red('\u2022 Deleted responders: \n', paste0('c("', paste(deleted_responders, collapse = '","'), '")')))

  # Check if the processed data is empty
  if (nrow(step1_res) == 0) {
    stop("The processed data is empty!")
  }

  return(step1_res)
}
# run robust regression model
process_lmrob_results <- function(data, threshold, ...) {
  # Safely apply lmrob function
  safelmrob <- purrr::safely(.f = robustbase::lmrob)

  # Process data using data.table syntax for efficiency
  temp1 <- data[, `:=`(safe_lmrob = purrr::map(data, \(df, ...) safelmrob(..., data = df), ...))
  ][, `:=`(
    model_lmrob = purrr::map(safe_lmrob, "result"),
    error_msg = purrr::map_chr(safe_lmrob, \(x) if (is.null(x$error)) "" else x$error$message),
    warning_msg = purrr::map_chr(safe_lmrob, \(x) if (is.null(x$warning)) "" else x$warning$message)
  )][, `:=`(
    residuals = purrr::pmap(list(model_lmrob, error_msg, warning_msg),
                            \(x, e, w) if (e == "" && w == "") {return(residuals(x))} else {return(NULL)}),
    predict = purrr::pmap(list(model_lmrob, error_msg, warning_msg),
                          \(x, e, w) if (e == "" && w == "") {return(predict(x))} else {return(NULL)}))
  ][, `:=`(mean_residual = purrr::map_dbl(residuals, \(r) mean(r, na.rm = TRUE)),
           sd_residual = purrr::map_dbl(residuals, \(r) sd(r, na.rm = TRUE)))
  ][, `:=`(outliers = purrr::pmap(list(residuals, mean_residual, sd_residual),\(r, m, sd) if (length(r) > 0) abs(r - m) > threshold * sd else NULL))][]


  # Clean up temporary columns and expand data
  temp2 <- temp1[, c("safe_lmrob", "model_lmrob", "error_msg", "warning_msg",
                     "residuals", "mean_residual", "sd_residual") := NULL][, {
                       dt <- data.table::as.data.table(data[[1]])
                       dt[, `:=`(
                         predict = unlist(predict),
                         outliers = unlist(outliers))]
                       dt}, by = responder]

  return(temp2)
}
# set robust regression
remove_outliers_using_ransac <- function(data, threshold, tuning.chi = 1.548, k.max = 1000, maxit.scale = 1000, max.it = 1000) {
  # Count initial responders
  begin_responder <- unique(data[, .(responder)])

  # Generate nested data format
  data <- data[, .(data = list(.SD)), by = responder]

  # Set RANSAC parameters
  control_params <- robustbase::lmrob.control(tuning.chi = tuning.chi, k.max = k.max, maxit.scale = maxit.scale, max.it = max.it)

  #Print message and check for errors and warnings
  message(crayon::cyan("\u2022 Running RANSAC Robust Regression:"))

  # Process data using RANSAC
  tryCatch({
    lm_results <- process_lmrob_results(data = data, threshold = threshold,
                                        weight ~ seq_days + I(seq_days^2),
                                        control = control_params)
    message(crayon::cyan("\u2022 RANSAC Robust Regression succeeded!"))

    # Count remaining responders after outlier removal
    end_responder <- unique(lm_results[outliers == FALSE, .(responder)])
    responder_to_delete <- begin_responder[!end_responder, on = "responder"]
    deleted_responders <- responder_to_delete$responder

    # Print information about deleted responders
    if (nrow(responder_to_delete) > 0) {
      message(crayon::red(paste0("\u2022 Detecting outliers using model will delete responders: ",
                                 nrow(responder_to_delete))))
      message(crayon::red(paste0('\u2022 Deleted responders: \n',
                                 'c("', paste(deleted_responders, collapse = '","'), '")')))
    } else {
      message(crayon::cyan("\u2022 The outliers detected by Robust model will not delete responder."))
    }

    # Remove outliers and affected responders
    lm_results[!responder %in% responder_to_delete$responder]
  }, error = function(e) {
    stop(crayon::red(paste("Error:", conditionMessage(e))))
  })
}
# get the maximum/minimum weight
get_extreme_weights <- function(data, seq_days, direction, weight_type) {
  data[, keyby = .(responder), `:=`(temp, data.table::frankv(direction * seq_days, ties.method = "dense") <= 2)]
  filtered_data <- data[temp == TRUE, keyby = .(responder, location), .(temp_weight = stats::median(predict))]
  data.table::setnames(filtered_data, "temp_weight", weight_type)
  return(filtered_data)
}
# check minimum entry weight and maximum exit wieght 
validate_responder_weights <- function(data, entry_weight_limit = 60, exit_weight_limit = 85) {
  # Filter out outliers
  filtered_data <- data[outliers == FALSE]

  # Get minimum weight
  min_weights <- get_extreme_weights(filtered_data, seq_days, 1, "min_weight")

  # Identify responders with entry weight exceeding the limit
  overweight_responders <- unique(min_weights[min_weight > (entry_weight_limit * 1000), .(responder)])
  num_overweight <- nrow(overweight_responders)

  # Log overweight responders
  if (num_overweight > 0) {
    message(crayon::red(paste0("\u2022 Removing begin_test_weight >", entry_weight_limit,
                               "kg records will delete responders:", num_overweight)))
  } else {
    message(crayon::cyan(paste0("\u2022 All responders' begin_test_weight are less than or equal to ",
                                 entry_weight_limit, "kg.")))
  }

  # Remove overweight responders
  data_filtered <- data[!responder %in% overweight_responders$responder]

  # Get maximum weight
  max_weights <- get_extreme_weights(data_filtered, seq_days, -1, "max_weight")

  # Identify responders with exit weight below the limit
  underweight_responders <- unique(max_weights[max_weight < (exit_weight_limit * 1000), .(responder)])
  num_underweight <- nrow(underweight_responders)

  # Log underweight responders
  if (num_underweight > 0) {
    message(crayon::red(paste0("\u2022 Removing end_test_weight <", exit_weight_limit, "kg records will delete responders: ", num_underweight)))
    deleted_responders <- c(overweight_responders$responder, underweight_responders$responder)
    message(crayon::red('\u2022 Deleted responders: \n', paste0('c("', paste(deleted_responders, collapse = '","'), '")')))
    #message(crayon::red('\u2022 Deleted responders: \n', paste0('c("', paste(deleted_responders, collapse = '","'), '")')))
  } else {
    message(crayon::cyan(paste0("\u2022 All responders' end_test_weight are more than or equal to ",
                                 exit_weight_limit, "kg.")))
  }

  # Return data for responders who passed weight criteria
  passed_responders <- data_filtered[!responder %in% underweight_responders$responder]
  return(passed_responders[, !c("temp")])
}
# run simple linear regression model
process_lm_results <- function(data, ...) {
  safelm = purrr::safely(.f = stats::lm)
  temp1 <- data[outliers == FALSE]
  temp2 <- temp1[, .(data = list(.SD)), by = responder
  ][, `:=`(safe_lm, purrr::map(data, \(df, ...) safelm(..., data = df), ...))
  ][, `:=`(safe_lm = purrr::map(safe_lm, "result"),
           error_msg = purrr::map_chr(safe_lm, \(x) if (is.null(x$error)) "" else x$error$message),
           warning_msg = purrr::map_chr(safe_lm, \(x) if (is.null(x$warning)) "" else x$warning$message))
  ][, `:=`(lm_predict, purrr::map2(safe_lm, warning_msg, \(x, w) if (w == "") stats::predict(x) else NA))
  ][, `:=`(lm_slope, purrr::map(safe_lm, \(x) coef(x)["seq_days"]))
  ][, `:=`(r_squared, purrr::map_dbl(safe_lm, \(x) if (!is.null(x)) summary(x)$r.squared else NA))]

  final <- temp2[, c("responder", "lm_slope", "r_squared")]
  final[, lm_slope := unlist(lm_slope)]
  return(final)
}
# parameters check
validate_arguments <- function(threshold, my_break, range_offset) {
  # Validate input threshold
  if (!is.numeric(threshold) || length(threshold) != 1 || threshold < 0 || threshold > 2) {
    stop("Argument 'threshold' should be a single numeric value between 0 and 2")
  }

  if (!is.null(my_break) && (!is.numeric(my_break) || length(my_break) != 2 || any(my_break < 0))) {
    stop("Argument 'my_break' should be a numeric vector of length 2 with non-negative values or NULL")
  }
  if (!is.numeric(range_offset) || length(range_offset) != 1 || range_offset < 0 || range_offset > 1) {
    stop("Argument 'range_offset' should be a single numeric value in the range [0, 1]")
  }
}
# cut weight in range
cut_weight <- function(data, my_break, range_offset) {
  # Convert my_break to grams to match weight representation in data
  my_break <- my_break * 1000
  # Generate actual break points using the given range and offset
  actual_breaks <- c(my_break[1] - range_offset * 1000, my_break[2] + range_offset * 1000)
  # Select weights within the specified range
  data <- data[predict >= actual_breaks[1] & predict <= actual_breaks[2], ]
  # Add a 'stage' column to represent the selected weight range
  data[, `:=`(stage, paste0(my_break[1] / 1000, "-", my_break[2] / 1000))]
  return(data)
}
# set simple linear regression model
calculate_adg_and_clean_data <- function(data, my_break, range_offset) {
  # Create a deep copy of the input data
  data <- data.table::copy(data)

  # Print message
  message(crayon::cyan("\u2022 Running Simple Linear Regression"))

  # Main function execution wrapped in tryCatch for error handling
  final <- tryCatch({
    if (!is.null(my_break)) {
      # Process data with specified weight break
      cut_data <- cut_weight(data = data, my_break = my_break, range_offset = range_offset)
      slopes_cut <- process_lm_results(data = cut_data, weight ~ seq_days)
      cat(crayon::cyan(paste0("\u2022 Calculate ADG at ", my_break[1], "~", my_break[2], "kg weight range using Simple Linear Regression succeeded!\n")))

      # Merge processed data and calculate additional metrics
      final <- merge(cut_data, slopes_cut, by = "responder")[, .(responder, location, stage, date, seq_in_location, seq_days, seq_in_day, weight, predict, r_squared, lm_slope, outliers)]
      temp_weight_get <- final[outliers == FALSE]
      temp_min_weight <- get_extreme_weights(data = temp_weight_get, seq_days, 1, "min_weight_cut")
      temp_max_weight <- get_extreme_weights(data = temp_weight_get, seq_days, -1, "max_weight_cut")

      # Calculate additional information
      info_temp_date <- data.table::copy(final)[, .(start_date_cut = min(date), end_date_cut = max(date)), by = responder]
      info_temp_base <- unique(final[, .(responder, stage, r_squared, lm_slope)])
      info_temp <- data.table::merge.data.table(info_temp_base, info_temp_date)
      weight_temp <- data.table::merge.data.table(temp_min_weight, temp_max_weight)
      temp_final <- data.table::merge.data.table(info_temp, weight_temp)

      # Calculate stage days and prepare final output
      temp_final <- temp_final[, stage_days := (my_break[2] * 1000 - my_break[1] * 1000) / lm_slope]
      temp_final <- temp_final[, .(responder, location, stage, start_date_cut, min_weight_cut, end_date_cut, max_weight_cut, r_squared, lm_slope, stage_days)]
      fin <- list(adg_info = temp_final, adg_data = final)
    } else {
      # Process all data without weight break
      slopes <- process_lm_results(data = data, weight ~ seq_days)
      message(crayon::cyan("\u2022 Calculate ADG using Simple Linear Regression succeeded!"))

      # Merge processed data and calculate additional metrics
      final <- merge(data, slopes, by = "responder")
      temp_weight_get <- final[outliers == FALSE]
      temp_min_weight <- get_extreme_weights(data = temp_weight_get, seq_days, 1, "min_weight_origin")
      temp_max_weight <- get_extreme_weights(data = temp_weight_get, seq_days, -1, "max_weight_origin")

      # Calculate additional information
      info_temp_date <- data.table::copy(final)[, .(start_date_origin = min(date), end_date_origin = max(date)), by = responder]
      info_temp_base <- unique(final[, .(responder, r_squared, lm_slope)])
      info_temp <- data.table::merge.data.table(info_temp_base, info_temp_date)
      weight_temp <- data.table::merge.data.table(temp_min_weight, temp_max_weight)
      temp_final <- data.table::merge.data.table(info_temp, weight_temp)

      # Prepare final output
      temp_final <- temp_final[, .(responder, location, start_date_origin, min_weight_origin, end_date_origin, max_weight_origin, r_squared, lm_slope)]
      fin <- list(adg_info = temp_final, adg_data = final)
    }
  }, error = function(e) {
    # Error handling
    message(crayon::red("\u2022 Error: ", conditionMessage(e)))
    stop("Execution error, the program has stopped")
  })

  return(final)
}
# create adg plots
create_adg_plots <- function(data, my_break) {
  # Prepare data: add color_judge column and group by location
  data <- data[, `:=`(color_judge, data.table::fifelse(outliers == F, "Normal", "Outlier"))
  ][, .(data = list(.SD)), location]

  # Create plots for each location
  data[, `:=`(plot, purrr::map2(data, location, function(.x, .y) {
    # Calculate slopes and R-squared values for each responder
    slopes_and_r_squared <- .x[, .(lm_slope = unique(lm_slope), r_squared = unique(r_squared)), by = responder]

    # Prepare text labels based on whether my_break is provided
    if (!is.null(my_break)) {
      slopes_and_r_squared[, day_diff := (my_break[2] * 1000 - my_break[1] * 1000) / lm_slope]
      slopes_and_r_squared[, day_text := sprintf("Slope: %.2f, R^2: %.2f\n%d~%d kg: %.1f days", lm_slope, r_squared, my_break[1], my_break[2], day_diff)]
    } else {
      slopes_and_r_squared[, day_text := sprintf("Slope: %.2f, R^2: %.2f", lm_slope, r_squared)]
    }

    # Create ggplot object
    ggplot2::ggplot(data = .x, ggplot2::aes(x = date, y = weight)) +
      # Set theme
      ggplot2::theme_bw() +
      # Add points for each data point, colored by outlier status
      ggplot2::geom_point(ggplot2::aes(col = color_judge), size = 1, na.rm = T) +
      # Set color scale for normal and outlier points
      ggplot2::scale_color_manual(values = c(Normal = "#38b48b", Outlier = "#b81a35"), name = "robust regression") +
      # Format x-axis (date)
      ggplot2::scale_x_date(date_breaks = "2 day", date_labels = "%m-%d") +
      # Add prediction line
      ggplot2::geom_line(ggplot2::aes(x = date, y = predict), na.rm = T) +
      # Create separate plots for each responder
      ggplot2::facet_wrap( ~ as.numeric(responder), ncol = 2) +
      # Set y-axis scale
      ggplot2::scale_y_continuous(breaks = seq(15000, 130000, 15000), limits = c(15000, 130000)) +
      # Add title
      ggplot2::labs(title = paste("Location:", .y)) +
      # Customize theme elements
      ggplot2::theme(legend.position = "bottom",
                     legend.title = ggplot2::element_text(size = 20),
                     legend.text = ggplot2::element_text(size = 20),
                     axis.text.x = ggplot2::element_text(angle = -90, size = 10),
                     plot.title = ggplot2::element_text(size = 25, face = "bold")
      ) +
      # Add horizontal reference lines
      ggplot2::geom_hline(yintercept = 30000, linetype = "dashed", color = "#aed0ee") +
      ggplot2::geom_hline(yintercept = 60000, linetype = "dashed", color = "#aed0ee") +
      ggplot2::geom_hline(yintercept = 115000, linetype = "dashed", color = "#aed0ee") +
      #ggplot2::geom_hline(yintercept = 120000, linetype = "dashed", color = "#aed0ee") +
      # Add text annotations for slope and R-squared
      ggplot2::geom_text(data = slopes_and_r_squared, mapping = ggplot2::aes(label = day_text, x = min(.x$date), y = 130000, group = responder), hjust = 0, vjust = 1, size = 3)
  }))]

  # Return the data with added plots
  return(data)
}
# save plots
save_adg_plots <- function(data, my_break, save_path) {
  # Add argument checks
  if (!is.character(save_path) || length(save_path) != 1) {
    stop("Argument 'save_path' should be a single character string")
  }
  if (!dir.exists(save_path)) {
    stop(paste0("Directory '", save_path, "' does not exist"))
  }

  # Calculate the number of responders and days for each location
  location_dims <- data[, .(n_responders = data.table::uniqueN(data[[1]]$responder),
                            n_days = data.table::uniqueN(data[[1]]$date)), by = location]

  # Adjust the width and height of the images
  adjusted_dims <- location_dims[, .(width = 0.5 * n_days, height = 5 * n_responders)]

  # Generate filenames for saving plots
  filename <- if (!is.null(my_break)) {
    # If my_break is provided, include weight range in the filename
    weight_range <- paste0(my_break[1], "-", my_break[2])
    file.path(save_path, paste0("location_", data$location, "_", weight_range, "_growth.png"))
  } else {
    # If my_break is not provided, use a simpler filename
    file.path(save_path, paste0("location_", data$location, "_growth.png"))
  }

  # Save the plots
  purrr::walk2(filename, data$plot, function(file, plot, width, height) {
    ggplot2::ggsave(filename = file, plot = plot, width = width, height = height, units = "cm", dpi = "retina")
  }, width = adjusted_dims$width, height = adjusted_dims$height)
}
